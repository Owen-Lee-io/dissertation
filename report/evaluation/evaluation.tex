\section{Face tracking}
\label{section:face_tracking}
Face tracking was proposed in Section \ref{section:face_tracking_impl} as an alternative to detecting the face in each frame independently.
From the implementation alone, it is unclear as to whether or not it is beneficial. To answer this, several separate aspects of the algorithm must be evaluated. 
Specifically, any described performance gains must be shown clearly as working across stationary scenarios and situations with movement of the face being tracked. Furthermore, it must be ensured that face tracking is not less accurate than simply repeatedly detecting the face in each frame. To evaluate these properties several metrics are defined and are measured across a variety of test videos.
\paragraph{Research questions}
\begin{itemize}
    \item Does face tracking provide a performance boost over face detection?
    \item Does face tracking have the same fidelity as face detection?
    \item Does face tracking maintain its accuracy under increasing motion?
    \item What value should the \texttt{threshold} take?\footnote{As defined in the pseudocode in Section \ref{section:face_tracking_impl} the \texttt{threshold} value defines when the face tracker redetects the face}
\end{itemize}
% Three main questions: 
% -is it a performance gain?  (for all videos)
% -is it resistant to motion?
% -is it as accurate?
% -effect on HR accuracy?
\paragraph{Dataset}
In order to better understand the performance of face tracking, a test set of several videos with varying amounts of movement was used. Some of the videos were taken from the MAHNOB dataset \cite{Mahnob}, which forms one of the key sources of data for the evaluation of this project.
Initially, generated as a dataset for study into affective computing, it consists of several thousand videos of participants as they are exposed to stimuli, with their ECG responses being recorded. 
\\\\
MAHNOB \cite{Mahnob} only consists of videos where the participants are stationary and at a fixed distance from the camera, this alone, would not be adeqeuate for the testing of face tracking. Hence, it was augmented with several videos which I recorded with varying amounts and types of movement.
I recorded a video with strictly `translational' movement, that is, the size of the face of the user remains largely constant as they move from one side of the frame to the other.
Another more challenging kind of movement, denoted here as `rotational', is where the user rotates their face so that different parts of the face are in a view in different frames.
Intuitively, one would expect this to be more difficult for the face tracker to deal with, since points will come in and out of view regularly.
\paragraph{Metrics}
Face detection is a binary classification task. As an algorithm, it defines a boundary within which all pixels are defined as belonging to face or not.
As a result, if we consider face detection as a ground truth, the results of face tracking can be compared using standard classification metrics. In this case, I proceed by considering the following outcomes from the face tracker.
\begin{itemize}
   \item False negative (FN): pixel is incorrectly classified as not belonging to a face
   \item False positive (FP): pixel is incorrectly classified as belonging to a face
   \item True negative (TN): pixel is correctly classified as not belonging to a face 
   \item True positive (TP): pixel is correctly classified as belonging to a face 
\end{itemize}
These metrics can be combined to define the recall and precision of the output of the face tracker over a given frame. These respectively represent the rate at which true skin pixels are correctly identified as such and the likelihood that a skin prediction is correct.
\begin{equation*}
    \mathrm{recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}} \text{ and } \mathrm{precision} = \frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FP}}
\end{equation*}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{example-image-a}
   \caption{A labelled diagram outlining the four metrics defined above.} 
\end{figure}
\noindent
\paragraph{Computing the classification outcomes} The result of each face detection is represented as a matrix of zeros and ones over the size of the entire frame.
Pixels within the bounding box of the face have value one and pixels outside have value zero in this matrix. Using this representation, for a given frame, the output from the face detector, $\mathbf{D}$ and the output of the face tracker $\mathbf{T}$, we compute the metrics as follows: 
\begin{align*}
    \mathrm{FP} &= H(\neg{\mathbf{D}} \wedge \mathbf{T}) \\
    \mathrm{FN} &= H(\mathbf{D} \wedge \neg{\mathbf{T}})\\
    \mathrm{TP} &= H(\mathbf{D} \wedge \mathbf{T})\\
    \mathrm{TN} &= H(\neg{\mathbf{D}} \wedge \neg{\mathbf{T}})
\end{align*}
Under the following notation: 
\begin{itemize}
    \item The function $H(\mathbf{A})$ returns the number of ones present in the matrix $\mathbf{A}$
    \item $\wedge$ is an elementwise, bitwise AND 
    \item $\vee$ is an elementwise bitwise OR operation 
    \item $\neg$ is a NOT operator on each element in the matrix
\\\\
\end{itemize}
The time to process each frame is also recorded as a means of measuring the relative performance of each algorithm.
Finally, the distance moved by each set of points being tracked between frames is recorded. This metric acts a means of encoding the amount of movement in the video.
\paragraph{Results}

\subparagraph{Accuracy}
% The performance of the above algorithm, clearly depends on the proportion that each of the two branches are executed.
\subparagraph{Motion resistance}

\subparagraph{Performance cost}
% talk about redetection rates
Recall from Section \ref{section:face_tracking_impl} that the following inequality was introduced that describes the performance of face tracking.
\begin{equation*}
    \frac{R}{W} < \frac{f(n)-g(p,n)}{f(n)+s(p,f)}
\end{equation*}\footnote{Notation: $R$: number of redetections, $W$: number of frames considered, $f(n)$: time to detect a face in a frame of size $n$, $g(p,n)$: time to track $p$ points on a face of size $n$, $s(p,f)$: time to select $p$ points on a face of size $f$ }
The above inequality relates the rate of redetections ($R/W$) and the costs of several required algorithms. It was shown in Section \ref{section:face_tracking_impl} that when this inequality holds, face tracking provides a performance benefit.
In order to justify this, the value of the right hand side is evaluated experimentally on a variety of videos and is shown the exceed the value $R/W$.

\subparagraph{Thresholds}


% \paragraph{Correctness}

\section{Region selection}
\label{section:region_selection}
The problem of region selection does not, at an initial glance, lend itself to easy evaluation.
It is unclear, through reasoning exclusively, whether increasingly complex algorithms for skin detection provide any benefit to the overall accuracy of the heart rate prediction.
% In fact, it is only hypothesised that any form of filtering on the bounding box 
In Section \ref{ref:region_selection_impl} it was weakly hypothesised that minimising the number of non-skin pixels included in the mean colour would decrease the noise in the resulting signal. 
This was made under the further assumption that a less noisy signal would result in more accurate heart rate predictions. 
Underpinning these assumptions is the notion that any pixels in the background, that is within the bounding box of the face but not true skin pixels, will contain no predictive power regarding the heart rate of the user.
\\\\
Crucially, however, it is unclear as to whether or not there exists some tradeoff between the number of pixels considered and their individual fidelities. 
It could be reasonably argued that by considering more pixels, the resulting average becomes more resistant to noise at individual pixel level, say that caused by fluctuations in lighting, for example.
It is not immediately clear whether considering a small set of guaranteed skin pixels is better than considering a large number of noisy pixels.
\\\\
This evaluation, hence, is concerned with the validation of these assumptions.
\subsection{Skin tone detection}
\label{section:skin_tone_detection}
% Evaluate using the primitive vs basic skin tone range vs k-means vs bayesian 
\paragraph{Research question}
% is considering a subset of pixels even beneficial?
% what effect does it have on SNR?
% how does that affect overall accuracy?
\begin{itemize}
   \item Is considering a subset of pixels within the bounding box advantageous? 
   \item Does skin detection reduce the noise of the resulting colour signal?
   \item Does a less noisy signal improve accuracy of heart rate predictions?
\end{itemize}

\paragraph{Metrics}
%-effect of each on signal to noise ratio over the entirety of MAHNOB
%-effect on accuracy of overall hr prediction
%-time cost
\paragraph{Results}

% \subsection{}
% \paragraph{Research questions}
% % doe
% \paragraph{Metrics}
% \paragraph{Results}


\section{Heart rate isolation}
\subsection{Identifying the pulse signal}
\label{section:bss}
\paragraph{Research question}
% ICA vs PCA
\paragraph{Metrics}
\paragraph{Results}
%The PCA approach comes with the benefit of identifying the pulse signal as a natural part of the algorithm.

\subsection{Extracting the heart rate from the pulse signal}
\subsubsection{Independent components analysis}
\label{section:ica_assumption}
\paragraph{Research question}
% evaluate correctness of assumption of maximum power from ICA applied to each signal
\paragraph{Metrics}
\paragraph{Results}

\subsubsection{Principal components analysis}
\paragraph{Research question}
% does component with most variance actually correspond to the pulse
\paragraph{Metrics}
\paragraph{Results}
%

% Not that important?
\subsection{Window and stride size}
\paragraph{Research question}
\paragraph{Metrics}
\paragraph{Results}


\section{Evaluation of remote heart rate sensing}
\subsection{Evaluation method}
\paragraph{Experimental setup}
\paragraph{Ethics}
% \section{Performance}
\subsection{Accuracy}
% cover stationary and exercise videos

\paragraph{Research questions}
% essentially this is where we evaluate vs a smartwatch
% two questions: 
% -is RPPG viable for stationary videos?
% -is it better than a smartwatch?
\paragraph{Metrics}
\paragraph{Results}

% these ones are EXTRAS just in case
% \subsection{Energy consumption}
% \paragraph{Research question}
% \paragraph{Metrics}
% \paragraph{Results}

% \subsection{Time cost}
% \paragraph{Resea-is RPPG viable for stationary videos?
% -is it better than a smartwatch?rch question}
% \paragraph{Metrics}
% \paragraph{Results}

\section{Summary}