@Article{skinDataset,
author="Rajen Bhatt, Abhinav Dhall",
title="Skin Segmentation Dataset", 
url="https://archive.ics.uci.edu/ml/datasets/skin+segmentation#",
journal="UCI Machine Learning Repository"
}
@Article{vanderKooij2019,
author={van der Kooij, Koen M.
and Naber, Marnix},
title={An open-source remote heart rate imaging method with practical apparatus and algorithms},
journal={Behavior Research Methods},
year={2019},
volume={51},
number={5},
pages={2106-2119},
abstract={Recent developments in computer science and digital image processing have enabled the extraction of an individual's heart pulsations from pixel changes in recorded video images of human skin surfaces. This method is termed remote photoplethysmography (rPPG) and can be achieved with consumer-level cameras (e.g., a webcam or mobile camera). The goal of the present publication is two-fold. First, we aim to organize future rPPG software developments in a tractable and nontechnical manner, such that the public gains access to a basic open-source rPPG code, comes to understand its utility, and can follow its most recent progressions. The second goal is to investigate rPPG's accuracy in detecting heart rates from the skin surfaces of several body parts after physical exercise and under ambient lighting conditions with a consumer-level camera. We report that rPPG is highly accurate when the camera is aimed at facial skin tissue, but that the heart rate recordings from wrist regions are less reliable, and recordings from the calves are unreliable. Facial rPPG remained accurate despite the high heart rates after exercise. The proposed research procedures and the experimental findings provide guidelines for future studies on rPPG.},
issn={1554-3528},
doi={10.3758/s13428-019-01256-8},
url={https://doi.org/10.3758/s13428-019-01256-8}
}
@workshop{LucasKanade,
author = {Bruce D. Lucas and Takeo Kanade},
title = {An Iterative Image Registration Technique with an Application to Stereo Vision (DARPA)},
booktitle = {Proceedings of the 1981 DARPA Image Understanding Workshop},
year = {1981},
month = {April},
pages = {121-130},
} 
@Article{Mahnob,
author = {M. Soleymani, J. Lichtenauer, T. Pun and M. Pantic.},
title = {"A multimodal database for affect recognition and implicit tagging"},
year = {2012},
month = {April},
pages = {42-55},
journal={IEEE Transactions on Affective Computing. 3},
}
@Article{Verkruysse2008,
author={Verkruysse, Wim
and Svaasand, Lars O.
and Nelson, J. Stuart},
title={Remote plethysmographic imaging using ambient light},
journal={Optics express},
year={2008},
month={Dec},
day={22},
volume={16},
number={26},
pages={21434-21445},
keywords={Diagnostic Imaging/*methods},
keywords={Equipment Design},
keywords={Exercise},
keywords={Heart Rate},
keywords={Hemoglobins/chemistry},
keywords={Humans},
keywords={*Light},
keywords={Male},
keywords={Monitoring, Physiologic/*methods},
keywords={Oxygen/chemistry},
keywords={Plethysmography/*instrumentation/*methods},
keywords={Respiration},
keywords={Time Factors},
keywords={Video Recording},
abstract={Plethysmographic signals were measured remotely (> 1m) using ambient light and a simple consumer level digital camera in movie mode. Heart and respiration rates could be quantified up to several harmonics. Although the green channel featuring the strongest plethysmographic signal, corresponding to an absorption peak by (oxy-) hemoglobin, the red and blue channels also contained plethysmographic information. The results show that ambient light photo-plethysmography may be useful for medical purposes such as characterization of vascular skin lesions (e.g., port wine stains) and remote sensing of vital signs (e.g., heart and respiration rates) for triage or sports purposes.},
note={19104573[pmid]},
note={PMC2717852[pmcid]},
note={175396[PII]},
issn={1094-4087},
doi={10.1364/oe.16.021434},
url={https://pubmed.ncbi.nlm.nih.gov/19104573}
}
@InProceedings{Balakrishnan_2013_CVPR,
author = {Balakrishnan, Guha and Durand, Fredo and Guttag, John},
title = {Detecting Pulse from Head Motions in Video},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2013}
} 
@article{poh2010non,
  title={Non-contact, automated cardiac pulse measurements using video imaging and blind source separation.},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={Optics express},
  volume={18},
  number={10},
  pages={10762--10774},
  year={2010},
  publisher={Optical Society of America}
}
@Article{Viola2004,
author={Viola, Paul
and Jones, Michael J.},
title={Robust Real-Time Face Detection},
journal={International Journal of Computer Vision},
year={2004},
volume={57},
number={2},
pages={137-154},
abstract={This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
issn={1573-1405},
doi={10.1023/B:VISI.0000013087.49260.fb},
url={https://doi.org/10.1023/B:VISI.0000013087.49260.fb}
}
@ARTICLE{655647,  author={H. A. {Rowley} and S. {Baluja} and T. {Kanade}},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},  title={Neural network-based face detection},   year={1998},  volume={20},  number={1},  pages={23-38},}
@INPROCEEDINGS{v-j-vs-ann,  author={M. {Da'san} and A. {Alqudah} and O. {Debeir}},  booktitle={2015 International Conference on Information and Communication Technology Research (ICTRC)},  title={Face detection using Viola and Jones method and neural networks},   year={2015},  volume={},  number={},  pages={40-43},}
@Inbook{Fleet2006,
author="Fleet, D.
and Weiss, Y.",
editor="Paragios, Nikos
and Chen, Yunmei
and Faugeras, Olivier",
title="Optical Flow Estimation",
bookTitle="Handbook of Mathematical Models in Computer Vision",
year="2006",
publisher="Springer US",
address="Boston, MA",
pages="237--257",
abstract="This chapter provides a tutorial introduction to gradient-based optical flow estimation. We discuss least-squares and robust estimators, iterative coarse-to-fine refinement, different forms of parametric motion models, different conservation assumptions, probabilistic formulations, and robust mixture models.",
isbn="978-0-387-28831-4",
doi="10.1007/0-387-28831-7_15",
url="https://doi.org/10.1007/0-387-28831-7_15"
}
@INPROCEEDINGS{
ShiTomasi,  author={ {Jianbo Shi} and  {Tomasi}},  booktitle={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},  title={Good features to track},   year={1994},  volume={},  number={},  pages={593-600},
}
@article{Cherry,
author = {Cherry,E. Colin },
title = {Some Experiments on the Recognition of Speech, with One and with Two Ears},
journal = {The Journal of the Acoustical Society of America},
volume = {25},
number = {5},
pages = {975-979},
year = {1953},
doi = {10.1121/1.1907229},

URL = { 
        https://doi.org/10.1121/1.1907229
    
},
eprint = { 
        https://doi.org/10.1121/1.1907229
    
}

}

@article{novel,
	Abstract = {In this paper we present a novel health monitoring method by estimating the heart rate and respiratory rate using an RGB camera. The heart rate and the respiratory rate are estimated from the photoplethysmography (PPG) and the respiratory motion. The method mainly operates by using the green spectrum of the RGB camera to generate a multivariate PPG signal to perform multivariate de-noising on the video signal to extract the resultant PPG signal. A periodicity based voting scheme (PVS) was used to measure the heart rate and respiratory rate from the estimated PPG signal. We evaluated our proposed method with a state of the art heart rate measuring method for two scenarios using the MAHNOB-HCI database and a self collected naturalistic environment database. The methods were furthermore evaluated for various scenarios at naturalistic environments such as a motion variance session and a skin tone variance session. Our proposed method operated robustly during the experiments and outperformed the state of the art heart rate measuring methods by compensating the effects of the naturalistic environment.},
	An = {29188085},
	Author = {Hassan, M A and Malik, A S and Fofi, D and Saad, N and Meriaudeau, F},
	Date = {2017/10/04},
	Date-Added = {2020-04-04 17:13:45 +0100},
	Date-Modified = {2020-04-04 17:13:45 +0100},
	Db = {PubMed},
	Doi = {10.1364/BOE.8.004838},
	Isbn = {2156-7085; 2156-7085},
	J2 = {Biomed Opt Express},
	Journal = {Biomedical optics express},
	Keywords = {(330.0330) Vision, color, and visual optics; (330.7326) Visual optics, modeling},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5695935/},
	La = {eng},
	Month = {10},
	Number = {11},
	Pages = {4838--4854},
	Publisher = {Optical Society of America},
	Title = {Novel health monitoring method using an RGB camera},
	Ty = {JOUR},
	U1 = {29188085{$[$}pmid{$]$}},
	U2 = {PMC5695935{$[$}pmcid{$]$}},
	U4 = {292965{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/29188085},
	Volume = {8},
	Year = {2017},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29188085},
	Bdsk-Url-2 = {https://doi.org/10.1364/BOE.8.004838}}



@INPROCEEDINGS{mahnob-example,  author={X. {Li} and J. {Chen} and G. {Zhao} and M. {Pietikäinen}},  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},  title={Remote Heart Rate Measurement from Face Videos under Realistic Situations},   year={2014},  volume={},  number={},  pages={4264-4271},}

@INPROCEEDINGS{mahnob-example-2,  author={X. {Niu} and H. {Han} and S. {Shan} and X. {Chen}},  booktitle={2017 IEEE International Joint Conference on Biometrics (IJCB)},  title={Continuous heart rate measurement from face: A robust rPPG approach with distribution learning},   year={2017},  volume={},  number={},  pages={642-650},}

@misc{opencv,
  title = {{OpenCV} library},
  howpublished = {\url{opencv.org}},
  note = {Accessed: 2019-10}
}
@InProceedings{Chen_2018_ECCV,
author = {Chen, Weixuan and McDuff, Daniel},
title = {DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {September},
year = {2018}
} 

@ARTICLE{comparative,
  
AUTHOR={Wang, Chen and Pun, Thierry and Chanel, Guillaume},   
	 
TITLE={A Comparative Survey of Methods for Remote Heart Rate Detection From Frontal Face Videos},      
	
JOURNAL={Frontiers in Bioengineering and Biotechnology},      
	
VOLUME={6},      

PAGES={33},     
	
YEAR={2018},      
	  
URL={https://www.frontiersin.org/article/10.3389/fbioe.2018.00033},       
	
DOI={10.3389/fbioe.2018.00033},      
	
ISSN={2296-4185},   
   
ABSTRACT={Remotely measuring physiological activity can provide substantial benefits for both the medical and the affective computing applications. Recent research has proposed different methodologies for the unobtrusive detection of heart rate (HR) using human face recordings. These methods are based on subtle color changes or motions of the face due to cardiovascular activities, which are invisible to human eyes but can be captured by digital cameras. Several approaches have been proposed such as signal processing and machine learning. However, these methods are compared with different datasets, and there is consequently no consensus on method performance. In this article, we describe and evaluate several methods defined in literature, from 2008 until present day, for the remote detection of HR using human face recordings. The general HR processing pipeline is divided into three stages: face video processing, face blood volume pulse (BVP) signal extraction, and HR computation. Approaches presented in the paper are classified and grouped according to each stage. At each stage, algorithms are analyzed and compared based on their performance using the public database MAHNOB-HCI. Results found in this article are limited on MAHNOB-HCI dataset. Results show that extracted face skin area contains more BVP information. Blind source separation and peak detection methods are more robust with head motions for estimating HR.}
}
@INPROCEEDINGS{osman,  author={A. {Osman} and J. {Turcot} and R. E. {Kaliouby}},  booktitle={2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)},  title={Supervised learning approach to remote heart rate estimation from facial videos},   year={2015},  volume={1},  number={},  pages={1-6},}
@article{poh,
  title={Advancements in noncontact, multiparameter physiological measurements using a webcam},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={IEEE transactions on biomedical engineering},
  volume={58},
  number={1},
  pages={7--11},
  year={2010},
  publisher={IEEE}
}
@inproceedings{li,
  title={Remote heart rate measurement from face videos under realistic situations},
  author={Li, Xiaobai and Chen, Jie and Zhao, Guoying and Pietikainen, Matti},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4264--4271},
  year={2014}
}
@inproceedings{spec1,
  title={Real-time specular highlight removal using bilateral filtering},
  author={Yang, Qingxiong and Wang, Shengnan and Ahuja, Narendra},
  booktitle={European conference on computer vision},
  pages={87--100},
  year={2010},
  organization={Springer}
}

@article{spec2,
  title={Efficient and robust specular highlight removal},
  author={Yang, Qingxiong and Tang, Jinhui and Ahuja, Narendra},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={37},
  number={6},
  pages={1304--1311},
  year={2014},
  publisher={IEEE}
}

@inproceedings{spec3,
  title={Specular highlight removal in facial images},
  author={Li, Chen and Lin, Stephen and Zhou, Kun and Ikeuchi, Katsushi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={3107--3116},
  year={2017}
}
@article{souza2019heart,
  title={Heart Rate Estimation During Physical Exercise Using Wrist-Type Ppg Sensors},
  author={Souza, Thiago Toledo},
  year={2019},
  publisher={University of Windsor}
}

