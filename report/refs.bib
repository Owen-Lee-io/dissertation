@Article{skinDataset,
author="Rajen Bhatt, Abhinav Dhall",
title="Skin Segmentation Dataset", 
url="https://archive.ics.uci.edu/ml/datasets/skin+segmentation#",
journal="UCI Machine Learning Repository"
}
@Article{vanderKooij2019,
author={van der Kooij, Koen M.
and Naber, Marnix},
title={An open-source remote heart rate imaging method with practical apparatus and algorithms},
journal={Behavior Research Methods},
year={2019},
volume={51},
number={5},
pages={2106-2119},
abstract={Recent developments in computer science and digital image processing have enabled the extraction of an individual's heart pulsations from pixel changes in recorded video images of human skin surfaces. This method is termed remote photoplethysmography (rPPG) and can be achieved with consumer-level cameras (e.g., a webcam or mobile camera). The goal of the present publication is two-fold. First, we aim to organize future rPPG software developments in a tractable and nontechnical manner, such that the public gains access to a basic open-source rPPG code, comes to understand its utility, and can follow its most recent progressions. The second goal is to investigate rPPG's accuracy in detecting heart rates from the skin surfaces of several body parts after physical exercise and under ambient lighting conditions with a consumer-level camera. We report that rPPG is highly accurate when the camera is aimed at facial skin tissue, but that the heart rate recordings from wrist regions are less reliable, and recordings from the calves are unreliable. Facial rPPG remained accurate despite the high heart rates after exercise. The proposed research procedures and the experimental findings provide guidelines for future studies on rPPG.},
issn={1554-3528},
doi={10.3758/s13428-019-01256-8},
url={https://doi.org/10.3758/s13428-019-01256-8}
}
@workshop{LucasKanade,
author = {Bruce D. Lucas and Takeo Kanade},
title = {An Iterative Image Registration Technique with an Application to Stereo Vision (DARPA)},
booktitle = {Proceedings of the 1981 DARPA Image Understanding Workshop},
year = {1981},
month = {April},
pages = {121-130},
} 
@Article{Mahnob,
author = {M. Soleymani, J. Lichtenauer, T. Pun and M. Pantic.},
title = {"A multimodal database for affect recognition and implicit tagging"},
year = {2012},
month = {April},
pages = {42-55},
journal={IEEE Transactions on Affective Computing. 3},
}
@Article{Verkruysse2008,
author={Verkruysse, Wim
and Svaasand, Lars O.
and Nelson, J. Stuart},
title={Remote plethysmographic imaging using ambient light},
journal={Optics express},
year={2008},
month={Dec},
day={22},
volume={16},
number={26},
pages={21434-21445},
keywords={Diagnostic Imaging/*methods},
keywords={Equipment Design},
keywords={Exercise},
keywords={Heart Rate},
keywords={Hemoglobins/chemistry},
keywords={Humans},
keywords={*Light},
keywords={Male},
keywords={Monitoring, Physiologic/*methods},
keywords={Oxygen/chemistry},
keywords={Plethysmography/*instrumentation/*methods},
keywords={Respiration},
keywords={Time Factors},
keywords={Video Recording},
abstract={Plethysmographic signals were measured remotely (> 1m) using ambient light and a simple consumer level digital camera in movie mode. Heart and respiration rates could be quantified up to several harmonics. Although the green channel featuring the strongest plethysmographic signal, corresponding to an absorption peak by (oxy-) hemoglobin, the red and blue channels also contained plethysmographic information. The results show that ambient light photo-plethysmography may be useful for medical purposes such as characterization of vascular skin lesions (e.g., port wine stains) and remote sensing of vital signs (e.g., heart and respiration rates) for triage or sports purposes.},
note={19104573[pmid]},
note={PMC2717852[pmcid]},
note={175396[PII]},
issn={1094-4087},
doi={10.1364/oe.16.021434},
url={https://pubmed.ncbi.nlm.nih.gov/19104573}
}
@InProceedings{Balakrishnan_2013_CVPR,
author = {Balakrishnan, Guha and Durand, Fredo and Guttag, John},
title = {Detecting Pulse from Head Motions in Video},
booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2013}
} 
@article{poh2010non,
  title={Non-contact, automated cardiac pulse measurements using video imaging and blind source separation.},
  author={Poh, Ming-Zher and McDuff, Daniel J and Picard, Rosalind W},
  journal={Optics express},
  volume={18},
  number={10},
  pages={10762--10774},
  year={2010},
  publisher={Optical Society of America}
}
@Article{Viola2004,
author={Viola, Paul
and Jones, Michael J.},
title={Robust Real-Time Face Detection},
journal={International Journal of Computer Vision},
year={2004},
volume={57},
number={2},
pages={137-154},
abstract={This paper describes a face detection framework that is capable of processing images extremely rapidly while achieving high detection rates. There are three key contributions. The first is the introduction of a new image representation called the "Integral Image" which allows the features used by our detector to be computed very quickly. The second is a simple and efficient classifier which is built using the AdaBoost learning algorithm (Freund and Schapire, 1995) to select a small number of critical visual features from a very large set of potential features. The third contribution is a method for combining classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising face-like regions. A set of experiments in the domain of face detection is presented. The system yields face detection performance comparable to the best previous systems (Sung and Poggio, 1998; Rowley et al., 1998; Schneiderman and Kanade, 2000; Roth et al., 2000). Implemented on a conventional desktop, face detection proceeds at 15 frames per second.},
issn={1573-1405},
doi={10.1023/B:VISI.0000013087.49260.fb},
url={https://doi.org/10.1023/B:VISI.0000013087.49260.fb}
}
@ARTICLE{655647,  author={H. A. {Rowley} and S. {Baluja} and T. {Kanade}},  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},  title={Neural network-based face detection},   year={1998},  volume={20},  number={1},  pages={23-38},}
@INPROCEEDINGS{v-j-vs-ann,  author={M. {Da'san} and A. {Alqudah} and O. {Debeir}},  booktitle={2015 International Conference on Information and Communication Technology Research (ICTRC)},  title={Face detection using Viola and Jones method and neural networks},   year={2015},  volume={},  number={},  pages={40-43},}
@Inbook{Fleet2006,
author="Fleet, D.
and Weiss, Y.",
editor="Paragios, Nikos
and Chen, Yunmei
and Faugeras, Olivier",
title="Optical Flow Estimation",
bookTitle="Handbook of Mathematical Models in Computer Vision",
year="2006",
publisher="Springer US",
address="Boston, MA",
pages="237--257",
abstract="This chapter provides a tutorial introduction to gradient-based optical flow estimation. We discuss least-squares and robust estimators, iterative coarse-to-fine refinement, different forms of parametric motion models, different conservation assumptions, probabilistic formulations, and robust mixture models.",
isbn="978-0-387-28831-4",
doi="10.1007/0-387-28831-7_15",
url="https://doi.org/10.1007/0-387-28831-7_15"
}
@INPROCEEDINGS{
ShiTomasi,  author={ {Jianbo Shi} and  {Tomasi}},  booktitle={1994 Proceedings of IEEE Conference on Computer Vision and Pattern Recognition},  title={Good features to track},   year={1994},  volume={},  number={},  pages={593-600},
}
@article{Cherry,
author = {Cherry,E. Colin },
title = {Some Experiments on the Recognition of Speech, with One and with Two Ears},
journal = {The Journal of the Acoustical Society of America},
volume = {25},
number = {5},
pages = {975-979},
year = {1953},
doi = {10.1121/1.1907229},

URL = { 
        https://doi.org/10.1121/1.1907229
    
},
eprint = { 
        https://doi.org/10.1121/1.1907229
    
}

}

@article{novel,
	Abstract = {In this paper we present a novel health monitoring method by estimating the heart rate and respiratory rate using an RGB camera. The heart rate and the respiratory rate are estimated from the photoplethysmography (PPG) and the respiratory motion. The method mainly operates by using the green spectrum of the RGB camera to generate a multivariate PPG signal to perform multivariate de-noising on the video signal to extract the resultant PPG signal. A periodicity based voting scheme (PVS) was used to measure the heart rate and respiratory rate from the estimated PPG signal. We evaluated our proposed method with a state of the art heart rate measuring method for two scenarios using the MAHNOB-HCI database and a self collected naturalistic environment database. The methods were furthermore evaluated for various scenarios at naturalistic environments such as a motion variance session and a skin tone variance session. Our proposed method operated robustly during the experiments and outperformed the state of the art heart rate measuring methods by compensating the effects of the naturalistic environment.},
	An = {29188085},
	Author = {Hassan, M A and Malik, A S and Fofi, D and Saad, N and Meriaudeau, F},
	Date = {2017/10/04},
	Date-Added = {2020-04-04 17:13:45 +0100},
	Date-Modified = {2020-04-04 17:13:45 +0100},
	Db = {PubMed},
	Doi = {10.1364/BOE.8.004838},
	Isbn = {2156-7085; 2156-7085},
	J2 = {Biomed Opt Express},
	Journal = {Biomedical optics express},
	Keywords = {(330.0330) Vision, color, and visual optics; (330.7326) Visual optics, modeling},
	L2 = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5695935/},
	La = {eng},
	Month = {10},
	Number = {11},
	Pages = {4838--4854},
	Publisher = {Optical Society of America},
	Title = {Novel health monitoring method using an RGB camera},
	Ty = {JOUR},
	U1 = {29188085{$[$}pmid{$]$}},
	U2 = {PMC5695935{$[$}pmcid{$]$}},
	U4 = {292965{$[$}PII{$]$}},
	Url = {https://pubmed.ncbi.nlm.nih.gov/29188085},
	Volume = {8},
	Year = {2017},
	Bdsk-Url-1 = {https://pubmed.ncbi.nlm.nih.gov/29188085},
	Bdsk-Url-2 = {https://doi.org/10.1364/BOE.8.004838}}



@INPROCEEDINGS{mahnob-example,  author={X. {Li} and J. {Chen} and G. {Zhao} and M. {Pietikäinen}},  booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition},  title={Remote Heart Rate Measurement from Face Videos under Realistic Situations},   year={2014},  volume={},  number={},  pages={4264-4271},}

@INPROCEEDINGS{mahnob-example-2,  author={X. {Niu} and H. {Han} and S. {Shan} and X. {Chen}},  booktitle={2017 IEEE International Joint Conference on Biometrics (IJCB)},  title={Continuous heart rate measurement from face: A robust rPPG approach with distribution learning},   year={2017},  volume={},  number={},  pages={642-650},}

@misc{opencv,
  title = {{OpenCV} library},
  howpublished = {\url{opencv.org}},
  note = {Accessed: 2019-10}
}
@misc{opencv,
  title = {{OpenCV} library},
  howpublished = {\url{opencv.org}},
  note = {Accessed: 2019-10}
}
@misc{opencv,
  title = {{OpenCV} library},
  howpublished = {\url{opencv.org}},
  note = {Accessed: 2019-10}
}